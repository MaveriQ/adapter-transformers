{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7010cb8a-5755-40da-955a-a25bd2490b6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from data_collator import DataCollatorForLiltPretraining\n",
    "import argparse\n",
    "from pl_lilt_datamodule import LiltPretrainingDataModule\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5a62a09-0def-46a9-a9fd-59e8545d6e84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser = LiltPretrainingDataModule.add_model_specific_args(parser)\n",
    "args = parser.parse_args('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44b57dd0-ca1c-4499-b680-bbd17ce42771",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hj36wegi/.conda/envs/adapters/lib/python3.11/site-packages/transformers/models/layoutlmv2/feature_extraction_layoutlmv2.py:30: FutureWarning: The class LayoutLMv2FeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use LayoutLMv2ImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Loading cached processed dataset at /work/scratch/hj36wegi/data/rvl_cdip_processed/train/cache-46290f929498e386_*_of_00032.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering dataset for category : form\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /work/scratch/hj36wegi/data/rvl_cdip_processed/validation/cache-caf03d03c32e70fc_*_of_00032.arrow\n",
      "Loading cached processed dataset at /work/scratch/hj36wegi/data/rvl_cdip_processed/test/cache-438a5461cf4b2c7e_*_of_00032.arrow\n"
     ]
    }
   ],
   "source": [
    "dm = LiltPretrainingDataModule(args)\n",
    "dm.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3ee1982-b0fc-4f46-9f16-4cc6454da8a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = dm.dataset['train']\n",
    "tokenizer = dm.processor.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d86eb52-cdef-4bcc-9bcb-b87ab20cb0c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "examples = [dataset[i] for i in range(4)]\n",
    "batch = {k:[ex[k] for ex in examples] for k in examples[0].keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0a66c47-b417-4e82-b4ce-4c7bf8e4503d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'special_tokens_mask', 'bbox'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "759fad6e-4d5f-4cab-ae31-595022fbf0ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_len = 512\n",
    "bs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37151581-9f4d-4843-9326-0529c6182c34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': 1, 'attention_mask': 0, 'special_tokens_mask': 1, 'bbox': 0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_tokens = {'input_ids':tokenizer.pad_token_id,\n",
    "              'attention_mask':0,\n",
    "              'special_tokens_mask':1,\n",
    "              'bbox':0}\n",
    "pad_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bd90093-d0cd-4876-9c08-40092814dc21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pad(examples,key,pad_token_id):\n",
    "    if key=='bbox':\n",
    "        output_shape = (bs,seq_len,4)\n",
    "    else:\n",
    "        output_shape = (bs,seq_len)\n",
    "    output = torch.full(output_shape,pad_token_id)\n",
    "    \n",
    "    for i,example in enumerate(examples):\n",
    "        if tokenizer.padding_side == \"right\":\n",
    "            output[i, : example.shape[1]] = example\n",
    "        else:\n",
    "            output[i, -example.shape[1] :] = example\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f80b1241-dbb3-45d5-afec-c365f5e4a593",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collated = {}\n",
    "for key in batch.keys():\n",
    "    collated[key] = pad(batch[key],key,pad_tokens[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7cd3000-99a8-4264-b142-6cde64339329",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([4, 512]),\n",
       " torch.Size([4, 512]),\n",
       " torch.Size([4, 512]),\n",
       " torch.Size([4, 512, 4])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.shape for k,v in collated.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8cdd18bc-03c0-4938-aa20-6883efe5095f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'right'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.padding_side, tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6975ea2-a3d2-428e-b723-be24536f517c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "    batch = {k:[ex[k] for ex in examples] for k in examples[0].keys()}\n",
    "    bs = len(examples)\n",
    "    collated = {}\n",
    "    \n",
    "    for key in batch.keys():\n",
    "        collated[key] = pad(batch[key],key,pad_tokens[key])\n",
    "        \n",
    "    return collated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab4dc3ae-6743-4c3a-ba44-8736eff8a946",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0,   313, 25740,  ...,     1,     1,     1],\n",
       "         [    0, 24784, 18106,  ...,     1,     1,     1],\n",
       "         [    0, 26550, 43309,  ...,     1,     1,     1],\n",
       "         [    0, 24784, 18106,  ...,     1,     1,     1]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'special_tokens_mask': tensor([[1, 0, 0,  ..., 1, 1, 1],\n",
       "         [1, 0, 0,  ..., 1, 1, 1],\n",
       "         [1, 0, 0,  ..., 1, 1, 1],\n",
       "         [1, 0, 0,  ..., 1, 1, 1]]),\n",
       " 'bbox': tensor([[[  0,   0,   0,   0],\n",
       "          [ 75,  88, 119,  99],\n",
       "          [ 75,  88, 119,  99],\n",
       "          ...,\n",
       "          [  0,   0,   0,   0],\n",
       "          [  0,   0,   0,   0],\n",
       "          [  0,   0,   0,   0]],\n",
       " \n",
       "         [[  0,   0,   0,   0],\n",
       "          [383, 314, 449, 327],\n",
       "          [383, 314, 449, 327],\n",
       "          ...,\n",
       "          [  0,   0,   0,   0],\n",
       "          [  0,   0,   0,   0],\n",
       "          [  0,   0,   0,   0]],\n",
       " \n",
       "         [[  0,   0,   0,   0],\n",
       "          [186,  67, 376,  78],\n",
       "          [186,  67, 376,  78],\n",
       "          ...,\n",
       "          [  0,   0,   0,   0],\n",
       "          [  0,   0,   0,   0],\n",
       "          [  0,   0,   0,   0]],\n",
       " \n",
       "         [[  0,   0,   0,   0],\n",
       "          [ 51, 141, 132, 167],\n",
       "          [ 51, 141, 132, 167],\n",
       "          ...,\n",
       "          [  0,   0,   0,   0],\n",
       "          [  0,   0,   0,   0],\n",
       "          [  0,   0,   0,   0]]])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collate_fn(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a337c5d-4b33-4564-87c2-7cf089351463",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1541b4d9-0c9c-49b2-bd59-45e76d2eace2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
